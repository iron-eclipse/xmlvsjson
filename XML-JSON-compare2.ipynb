{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lib.openai_client import OpenAIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cache directories\n",
    "xml_cache_dir = './cache/xml'\n",
    "json_cache_dir = './cache/json'\n",
    "contract_cache_dir = './cache/contracts'\n",
    "result_cache_dir = './cache/results'\n",
    "\n",
    "for directory in [xml_cache_dir, json_cache_dir, contract_cache_dir, result_cache_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompts\n",
    "def load_prompts(mode):\n",
    "    if mode == 'xml':\n",
    "        with open('./prompts/generate_xml_from_contract.txt', 'r') as file:\n",
    "            generation_prompt = file.read()\n",
    "        with open('./prompts/generate_contract_from_xml.txt', 'r') as file:\n",
    "            reconstruction_prompt = file.read()\n",
    "    elif mode == 'json':\n",
    "        with open('./prompts/generate_json_from_contract.txt', 'r') as file:\n",
    "            generation_prompt = file.read()\n",
    "        with open('./prompts/generate_contract_from_json.txt', 'r') as file:\n",
    "            reconstruction_prompt = file.read()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Use 'xml' or 'json'.\")\n",
    "    \n",
    "    return generation_prompt, reconstruction_prompt\n",
    "\n",
    "xml_generation_prompt, xml_reconstruction_prompt = load_prompts('xml')\n",
    "json_generation_prompt, json_reconstruction_prompt = load_prompts('json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def load_contracts():\n",
    "    contract_dir = './contracts'\n",
    "    contract_files = [f for f in os.listdir(contract_dir) if f.endswith('.txt')]\n",
    "    contract_files.sort()\n",
    "    return contract_files\n",
    "\n",
    "def cleanup_contract(contract_text):\n",
    "    contract_text = re.sub(r'<scratchpad>.*?</scratchpad>', '', contract_text, flags=re.DOTALL)\n",
    "    contract_text = re.sub(r'<.*?>', '', contract_text)\n",
    "    contract_text = re.sub(r'^\\s*---\\s*$', '', contract_text, flags=re.MULTILINE)\n",
    "    contract_text = re.sub(r'\\n\\s*\\n', '\\n\\n', contract_text)\n",
    "    return contract_text.strip()\n",
    "\n",
    "def cleanup_generated_object(text, mode):\n",
    "    tag = 'xml_output' if mode == 'xml' else 'json_output'\n",
    "    pattern = f'<{tag}>.*?</{tag}>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(0).strip()\n",
    "    else:\n",
    "        print(f\"Warning: No <{tag}> tags found. Returning original text.\")\n",
    "        return text\n",
    "\n",
    "def get_cache_filename(base_dir, original_file, extension):\n",
    "    base_name = os.path.basename(original_file)\n",
    "    return os.path.join(base_dir, base_name.replace('.txt', extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client setup\n",
    "openaiclient = OpenAIClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing functions\n",
    "def generate_object(contract_text, mode):\n",
    "    openaiclient.reset_context()\n",
    "    prompt = (xml_generation_prompt if mode == 'xml' else json_generation_prompt)\n",
    "    prompt = prompt.replace(\"{{CONTRACT}}\", contract_text)\n",
    "    openaiclient.add_message(\"user\", prompt)\n",
    "    response = openaiclient.get_response()\n",
    "    return cleanup_generated_object(response, mode)\n",
    "\n",
    "def generate_contract_from_object(object_text, mode):\n",
    "    openaiclient.reset_context()\n",
    "    prompt = (xml_reconstruction_prompt if mode == 'xml' else json_reconstruction_prompt)\n",
    "    prompt = prompt.replace(f\"{{{{{'XML' if mode == 'xml' else 'JSON'}_DOCUMENT}}}}\", object_text)\n",
    "    openaiclient.add_message(\"user\", prompt)\n",
    "    response = openaiclient.get_response()\n",
    "    return cleanup_contract(response)\n",
    "\n",
    "def process_contract(contract_file, mode):\n",
    "    cache_dir = xml_cache_dir if mode == 'xml' else json_cache_dir\n",
    "    cache_file = get_cache_filename(cache_dir, contract_file, f'.{mode}')\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Using cached {mode.upper()} for {contract_file}\")\n",
    "        with open(cache_file, 'r') as f:\n",
    "            return f.read()\n",
    "    \n",
    "    print(f\"Generating new {mode.upper()} for {contract_file}\")\n",
    "    try:\n",
    "        with open(os.path.join('./contracts', contract_file), 'r') as f:\n",
    "            contract_text = f.read()\n",
    "        \n",
    "        generated_object = generate_object(contract_text, mode)\n",
    "        \n",
    "        with open(cache_file, 'w') as f:\n",
    "            f.write(generated_object)\n",
    "        \n",
    "        return generated_object\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {contract_file}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def reconstruct_contract(object_text, original_contract_file, mode):\n",
    "    cache_file = get_cache_filename(contract_cache_dir, original_contract_file, f'_reconstructed_{mode}.txt')\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Using cached reconstructed contract for {original_contract_file}\")\n",
    "        with open(cache_file, 'r') as f:\n",
    "            return f.read()\n",
    "    \n",
    "    print(f\"Generating new contract from {mode.upper()} for {original_contract_file}\")\n",
    "    reconstructed_contract = generate_contract_from_object(object_text, mode)\n",
    "\n",
    "    with open(cache_file, 'w') as f:\n",
    "        f.write(reconstructed_contract)\n",
    "\n",
    "    return reconstructed_contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding and comparison functions\n",
    "def create_embedding(text):\n",
    "    return openaiclient.get_embedding(text)\n",
    "\n",
    "def compare_embeddings(emb1, emb2):\n",
    "    return cosine_similarity([emb1], [emb2])[0][0]\n",
    "\n",
    "def save_results(similarities, mode):\n",
    "    cache_file = os.path.join(result_cache_dir, f\"similarities_{mode}.json\")\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump(similarities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main process\n",
    "def process_contracts(mode):\n",
    "    similarities = []\n",
    "    \n",
    "    for contract_file in load_contracts():\n",
    "        print(f\"Processing {contract_file}\")\n",
    "        \n",
    "        # Load original contract\n",
    "        with open(os.path.join('./contracts', contract_file), 'r') as f:\n",
    "            original_contract = f.read()\n",
    "        \n",
    "        # Generate XML/JSON object\n",
    "        generated_object = process_contract(contract_file, mode)\n",
    "        \n",
    "        if generated_object is not None:\n",
    "            # Reconstruct contract\n",
    "            reconstructed_contract = reconstruct_contract(generated_object, contract_file, mode)\n",
    "            \n",
    "            # Create embeddings\n",
    "            original_embedding = create_embedding(original_contract)\n",
    "            reconstructed_embedding = create_embedding(reconstructed_contract)\n",
    "            \n",
    "            # Compare embeddings\n",
    "            similarity = compare_embeddings(original_embedding, reconstructed_embedding)\n",
    "            similarities.append(similarity)\n",
    "            \n",
    "            print(f\"Similarity for {contract_file}: {similarity:.4f}\")\n",
    "        \n",
    "    save_results(similarities, mode)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing contracts using XML...\n",
      "Processing agreement_01.txt\n",
      "Generating new XML for agreement_01.txt\n",
      "Warning: No <xml_output> tags found. Returning original text.\n",
      "Generating new contract from XML for agreement_01.txt\n",
      "Similarity for agreement_01.txt: 0.3078\n",
      "Processing lease_01.txt\n",
      "Generating new XML for lease_01.txt\n",
      "Generating new contract from XML for lease_01.txt\n",
      "Similarity for lease_01.txt: 0.3523\n",
      "Processing media_01.txt\n",
      "Generating new XML for media_01.txt\n",
      "Generating new contract from XML for media_01.txt\n",
      "Similarity for media_01.txt: 0.3909\n",
      "Processing ngo_01.txt\n",
      "Generating new XML for ngo_01.txt\n",
      "Warning: No <xml_output> tags found. Returning original text.\n",
      "Generating new contract from XML for ngo_01.txt\n",
      "Similarity for ngo_01.txt: 0.2984\n",
      "Processing professional_01.txt\n",
      "Generating new XML for professional_01.txt\n",
      "Warning: No <xml_output> tags found. Returning original text.\n",
      "Generating new contract from XML for professional_01.txt\n",
      "Similarity for professional_01.txt: 0.4575\n",
      "Processing support_01.txt\n",
      "Generating new XML for support_01.txt\n",
      "Generating new contract from XML for support_01.txt\n",
      "Similarity for support_01.txt: 0.3391\n",
      "\n",
      "Processing contracts using JSON...\n",
      "Processing agreement_01.txt\n",
      "Generating new JSON for agreement_01.txt\n",
      "Generating new contract from JSON for agreement_01.txt\n",
      "Similarity for agreement_01.txt: 0.2715\n",
      "Processing lease_01.txt\n",
      "Generating new JSON for lease_01.txt\n",
      "Generating new contract from JSON for lease_01.txt\n",
      "Similarity for lease_01.txt: 0.2418\n",
      "Processing media_01.txt\n",
      "Generating new JSON for media_01.txt\n",
      "Generating new contract from JSON for media_01.txt\n",
      "Similarity for media_01.txt: 0.3645\n",
      "Processing ngo_01.txt\n",
      "Generating new JSON for ngo_01.txt\n",
      "Generating new contract from JSON for ngo_01.txt\n",
      "Similarity for ngo_01.txt: 0.2812\n",
      "Processing professional_01.txt\n",
      "Generating new JSON for professional_01.txt\n",
      "Generating new contract from JSON for professional_01.txt\n",
      "Similarity for professional_01.txt: 0.2875\n",
      "Processing support_01.txt\n",
      "Generating new JSON for support_01.txt\n",
      "Generating new contract from JSON for support_01.txt\n",
      "Similarity for support_01.txt: 0.3109\n"
     ]
    }
   ],
   "source": [
    "# Run the process for both XML and JSON\n",
    "print(\"Processing contracts using XML...\")\n",
    "xml_similarities = process_contracts('xml')\n",
    "\n",
    "print(\"\\nProcessing contracts using JSON...\")\n",
    "json_similarities = process_contracts('json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for XML:\n",
      "Average similarity: 0.3577\n",
      "Minimum similarity: 0.2984\n",
      "Maximum similarity: 0.4575\n",
      "\n",
      "Results for JSON:\n",
      "Average similarity: 0.2929\n",
      "Minimum similarity: 0.2418\n",
      "Maximum similarity: 0.3645\n",
      "\n",
      "Comparison:\n",
      "XML outperformed JSON by 6.48%\n"
     ]
    }
   ],
   "source": [
    "# Analyze and display results\n",
    "def print_results(similarities, mode):\n",
    "    print(f\"\\nResults for {mode.upper()}:\")\n",
    "    print(f\"Average similarity: {np.mean(similarities):.4f}\")\n",
    "    print(f\"Minimum similarity: {np.min(similarities):.4f}\")\n",
    "    print(f\"Maximum similarity: {np.max(similarities):.4f}\")\n",
    "\n",
    "print_results(xml_similarities, 'xml')\n",
    "print_results(json_similarities, 'json')\n",
    "\n",
    "# Compare XML and JSON performance\n",
    "xml_mean = np.mean(xml_similarities)\n",
    "json_mean = np.mean(json_similarities)\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "if xml_mean > json_mean:\n",
    "    print(f\"XML outperformed JSON by {(xml_mean - json_mean) * 100:.2f}%\")\n",
    "elif json_mean > xml_mean:\n",
    "    print(f\"JSON outperformed XML by {(json_mean - xml_mean) * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"XML and JSON performed equally well\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
